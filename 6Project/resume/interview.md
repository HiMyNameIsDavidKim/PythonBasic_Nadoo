# 면접
* 자신감과 진정성
<br><br>

## 🧐 사용 방법
* 질문에 대한 답변을 패드에 손으로 쓰며 외운다.
* 마크다운의 목차(Outline)를 클릭하여 펼친다.
* 질문만 보고 답변을 연습한다.
<br><br>



## 📋 Contents
### 딥러닝
### 머신러닝
### 통계학
### 데이터분석
### 알고리즘
### 자료구조
### 컴퓨터과학
### 필수
### 회사관심도
### 직무경험
### 프로젝트
### 압박
### 소프트스킬
<br><br>



## `[기술 면접]`
* 간결하고 쉽게 설명
<br><br>

### [딥러닝]
#### 딥러닝이란 무엇인가
* 머신러닝의 한 종류로 인공신경망을 기반으로 데이터에서 패턴을 찾아내는 알고리즘입니다.
#### 딥러닝과 머신러닝의 차이를 설명하라
* 딥러닝은 모델이 특징 추출, 학습을 자동으로 수행합니다.
* 머신러닝은 사람이 특징을 설계하고 모델은 학습만 합니다.
#### 오버피팅과 언더피팅의 차이점
* 오버피팅은 학습 데이터를 외우는 것처럼 과하게 학습하여 일반화 성능이 낮습니다.
* 언더피팅은 아직 학습 데이터의 패턴을 제대로 학습하지 못한 상태입니다.
#### FC layer와 CNN layer의 차이점을 설명하라
* FC layer는 모든 뉴런이 연결되어 있고 입력 데이터를 고차원 공간에서 다른 차원으로 변환합니다.
* CNN layer는 필터를 사용해서 주변 데이터와의 관계와 지역적 패턴을 추출합니다.
#### 비선형이란 무엇이고 왜 필요한가
* 비선형은 직선 즉 선형 함수로 설명할 수 없는 복잡한 관계를 뜻합니다.
* 어려운 문제들은 비선형성을 추가해 복잡한 패턴을 학습해야 해결할 수 있습니다.
#### sigmoid 대신 relu를 사용하는 이유를 설명하라
* sigmoid는 S자 형태로 음수에서 0에 가까워지고 양수에서 1에 가까워집니다.
* relu는 음수에서 0이고 양수에서 입력값 그대로를 출력합니다.
* sigmoid는 상대적으로 gradient vanishing 문제에 더 취약합니다. relu의 경우 출력 값의 상단 제한이 없지만 sigmoid의 경우 출력값이 0과 1 사이로 제한되기 때문에 기울기가 매우 작아지는 gradient vanishing 문제를 초래합니다.
#### relu가 곡선 함수를 근사하는 방법을 설명하라
* relu는 여러 뉴런의 활성화 상태를 조합해 복잡한 비선형 함수를 근사할 수 있습니다. 각 뉴런의 활성화 여부를 on/off하면 곡선 함수를 근사할 수 있습니다.
#### gradient vanishing의 근본적인 원인을 설명하라
* 활성화 함수의 영향, 체인룰의 영향 두가지가 있습니다. 시그모이드의 경우 활성화 함수의 기울기가 0에 가까워져 결국 가중치를 업데이트하지 못합니다. 이를 방지하기 위해 relu를 사용하더라도 기울기가 0인 구간이 여전히 존재하기 때문에 chain rule에 의해 역전파 과정에서 낮은 층까지 도달하면 기울기가 0에 급격하게 가까워져 업데이트가 되지 않는 문제가 있습니다.
#### gradient descent의 개념을 설명하라
* 손실함수를 최소화하기 위해 가중치를 반복 업데이트하는 최적화 알고리즘입니다.
* 손실함수가 가장 작은 지점이 최적값 즉 해인데, n차 함수 형태인 손실함수의 최솟값을 구하는 방법은 미분해서 0인 지점으로 다가가는 것입니다. 여기서 미분이 gradient, 0으로 다가가는 것이 descent 입니다.
#### 경사하강법 그래프의 x축과 y축의 의미를 설명하라
* x축은 모델의 가중치, y축은 loss value를 뜻합니다.
#### GD 중에 때때로 loss가 증가하는 이유를 설명하라
* 첫번째로 learning rate가 너무 크면 한번의 업데이트에서 minima를 지나칠 수 있습니다. 두번째로 미니 배치 간의 분포 차이로 인한 변동성이 있을 수 있습니다. 세번째로 loss function의 landscape가 복잡해 local minima를 탈출할 때 발생할 수 있습니다.
#### GD와 SGD의 차이를 설명하라
* GD는 전체 데이터셋을 모두 사용하여 느리지만 안정적으로 학습합니다.
* SGD는 데이터셋의 일부를 사용하여 빠르게 학습하지만 불안정할 수 있습니다.
#### RMSprop과 Adam에 대하여 설명하라
* RMSprop은 기울기의 제곱에 대한 지수이동평균을 이용해 학습률을 동적으로 조절하는 방법입니다. 기울기가 큰 파라미터의 학습률을 줄여 더 안정적으로 학습을 진행합니다.
* Adam은 여기에 모멘텀을 추가하여 더 빠르고 효율적으로 학습하는 방법입니다.
#### 모멘텀을 수식으로 설명하라
* 물리학적 관점의 관성을 알고리즘화한 것입니다. 기존 가중치에 속도인 모멘텀을 더해줍니다. 이번 단계의 속도는 이전 단계의 속도와 이번 단계의 기울기를 조합해 계산합니다.
#### backpropagation에 대하여 설명하라
* 입력에서 출력 방향인 순방향을 계산해 예측값을 구하고 loss를 구합니다.
* loss를 출력에서 입력 방향으로 전파하며 가중치를 얼마나 바꿔야 오차가 줄어드는지 계산합니다. 이것은 chain rule에 의해 각 가중치에 대한 그라디언트를 계산하면 얻을 수 있습니다. (그라디언트 = 현재 가중치가 얼마나 잘못되었는지에 대한 벡터)
* 계산된 가중치를 학습률과 곱해 모든 가중치를 업데이트 합니다.
#### local minima로 인해 딥러닝이 안되는 매커니즘을 설명하라
* 모델이 local minima에 빠지면 더 나은 global minima에 도달하지 못하고 성능 개선이 멈춰버립니다.
#### saddle point 문제에 대하여 설명하라
* 차원 공간에서 한 방향에서는 최소값을 가지지만 다른 방향에서는 최대값을 가지는 지점을 말합니다. 한 방향에서 미분이 0이 나오고 다른 방향을 줄이려다가 원래 방향의 값이 증가할 수 있는 문제로, 더이상 학습을 진행하지 않을 수 있습니다.
* 초기 값을 다양하게 설정하거나 모멘텀 기법을 사용하여 해결할 수 있습니다.
#### 찾은 해가 global minima인지 판단하는 방법은 무엇인가
* loss function landscape를 시각화하거나 다양한 초기값으로 학습해서 최소값에 변화가 있는지 비교해봅니다.
#### 지도학습과 비지도학습의 objective funtion과 차이를 설명하라
* 지도학습은 실제값과 예측값의 loss를 계산하고 최소화하는 방법을 사용합니다. (ex. MSE, CE)
* 비지도학습은 데이터의 구조를 파악하고 군집이나 밀도를 목표로 합니다. (ex. 클러스터링, PCA)
#### 과적합 방지를 위해 사용하는 방법을 모두 설명하라
* dropout, regularization, batch norm, 데이터 증강 기법, early stopping 등이 있습니다.
#### dropout의 개념과 사용하는 이유를 설명하라
* 드롭아웃은 학습 시 무작위로 무작위로 뉴런을 비활성화하여 특정 뉴런에 의존하지 않도록 합니다.
* 과적합을 방지하고 모델의 일반화 성능을 높일 수 있습니다.
#### 정규화(regularization)에 대하여 설명하라
* 과적합 방지를 위한 제약조건으로 L1, L2 등이 있습니다. 이 값을 실제 손실함수에 패널티로 더해주면 모델은 가중치의 크기를 줄이는 방향으로 학습합니다.
* L1은 lasso로 가중치의 절대값 합을 패널티로 부과합니다. 모델에 중요하지 않은 특성의 가중치를 0으로 만들어 희소성을 유지합니다.
* L2은 ridge로 가중치의 제곱 합을 패널티로 부과합니다. 전체적인 특성의 가중치를 작은 값으로 만들어 과적합을 방지합니다.
#### 정규화(norm)와 표준화(stand)의 차이점을 설명하라
* 정규화(normalization)는 데이터를 0에서 1 범위로 변환하는 것이고 표준화(standardization)는 평균은 0 분산은 1이 되도록 변환하는 것입니다.
#### 정규화(norm)을 하는 이유를 설명하라
* 학습 중에 특성 간의 크기 차이를 제거하고 특정 뉴런의 의존도가 너무 높지 않도록 하여 학습을 안정화 시킵니다.
#### batch normalization의 개념과 사용하는 이유를 설명하라
* 배치 노멀라이제이션은 각 미니배치 입력의 평균과 분산을 0과 1로 조절합니다. 따라서 초기값에 의해 특정 미니배치가 과하게 학습되는 과적합 현상을 방지해줍니다.
#### batch norm과 layer norm의 차이를 설명하라
* 입력 텐서의 (batch, 이미지 토큰 수, dim)이 (64, 196, 768)인 예시로 설명하겠습니다.
* batch norm은 같은 토큰 같은 dim에서 batch를 기준으로 값을 정규화하는 것입니다. 입력 값의 분포가 학습 중에 변하는 것을 방지합니다. 하지만 배치에 의존적이기 때문에 작은 배치에서는 효과가 불안정할 수 있습니다.
* layer norm은 같은 토큰 같은 batch에서 dim을 기준으로 값을 정규화하는 것입니다. 같은 샘플 내의 뉴런의 의존도 편향을 방지합니다. 따라서 배치에 독립적이고 작은 배치에서도 안정적으로 동작합니다.
#### 분포가 불균형한 데이터를 분류 할 때 발생하는 문제는 무엇인가
* 구성 비율이 낮은 클래스가 무시되어 모델이 편향되고 성능이 떨어집니다.
* 오버샘플링이나 언더샘플링을 사용하면 문제를 해결할 수 있습니다.
#### cost function과 activation function을 설명하라
* cost function은 loss function으로 실제값과 예측값의 차이를 계산합니다. (ex. MSE, CE)
* activation function은 뉴런의 출력을 결정하고 모델에 비선형성을 부여합니다. (ex. relu, softmax)
#### 파이토치와 텐서플로우의 특징과 차이를 설명하라
* 파이토치는 더 파이써닉한 코드라 가독성이 좋습니다. 또한 실행 중에 텐서를 이용해 동적으로 그래프를 그릴 수 있어 디버깅이 편합니다.
* 텐서플로우는 배포의 용이성과 텐서보드 시각화에 강점이 있습니다. 또한 미리 그래프를 선언해 정적인 그래프를 그릴 수 있어 속도가 빠릅니다.
#### 하이퍼 파라미터는 무엇인지 설명하라
* 학습 전에 사람이 직접 설정하는 파라미터로 모델의 성능에 큰 영향을 미칩니다.
* learning rate, batch size, epoch, dim, block 수 등이 있습니다.
#### weight initialization 개념과 종류를 설명하라
* 가중치의 초기값을 설정하는 방법으로 ±0.1 사이의 균일한 분포 값을 넣는 랜덤, 입출력 뉴런 수를 고려한 xavier 방법 등이 있습니다.
#### training set과 test set을 분리하는 이유를 설명하라
* 모델의 일반화 성능을 객관적으로 평가하기 위해서 입니다. 과적합된 경우 학습에 사용한 데이터는 모델이 이미 외우고 있을 수 있습니다.
#### validation set이 필요한 이유를 설명하라
* 하이퍼 파라미터 튜닝이나 학습 중간에 경과를 평가하기 위해서 사용합니다.
#### GPU를 사용하는 이유를 설명하라
* 병렬 연산이 가능해서 CPU보다 더 빠른 속도로 학습할 수 있습니다. 딥러닝은 행렬 연산을 많이 사용하기 때문에 GPU를 사용합니다.
#### GPU를 두개 사용하는 방법을 설명하라
* 배치를 나눠서 각 GPU에서 병렬로 데이터를 처리할 수 있습니다. 파이토치에서 분산학습 메서드인 DistributedDataParallel를 사용하면 됩니다.
#### 학습에 필요한 GPU 메모리를 계산하는 방법을 설명하라
* 배치크기 * 파라미터수 * 4(float32)로 계산할 수 있고 모델 (인스턴스, 그라디언트, 옵티마이저)를 고려해 4배 정도 됩니다.
#### 트랜스포머의 전체적인 구조를 설명하라
* 인코더-디코더 구조로 되어 있고 어텐션 레이어를 사용합니다. 인코더에는 셀프어텐션, 디코더에는 masked 셀프어텐션, 인코더-디코더 어텐션 구조로 되어 있습니다.
* 인코더와 디코더의 마지막에는 Feed Forwad Network가 있고 어텐션 레이어와 FFN 뒤에는 residual connection과 norm을 진행합니다.
* 입력이 들어오면 이를 임베딩으로 만들고 포지션 임베딩을 더해줍니다. 그리고 인코더-디코더 구조를 거친 뒤 최종 임베딩을 linear layer와 softmax를 거쳐 최종 결과를 냅니다.
#### 트랜스포머가 위치정보를 전달하는 방법을 설명하라
* 포지션 임베딩을 사용하여 위치 정보를 전달합니다. sin, cos 함수를 기반으로 인코딩하며 순차성은 있지만 의미 정보가 변질되지 않도록 ±1사이의 값입니다. 주기성을 이용하여 각 위치마다 고유한 패턴을 만들어냅니다.
#### 어텐션 매커니즘의 과정을 수식으로 설명하라
* 입력 임베딩에 Q, K, V 매트릭스를 내적해 Q, K, V 벡터를 먼저 얻을 수 있습니다.
* 현재 단어의 Q와 모든 단어의 K의 전치행렬을 각각 내적하여 각각의 어텐션 스코어를 구하고 이를 softmax 함수에 넣어 각각의 어텐션 웨이트를 구합니다.
* 각각의 어텐션 웨이트를 각각의 V와 곱한뒤 모두 더해 컨텍스트 벡터를 구할 수 있습니다.
* 이 컨텍스트 벡터는 QKV 벡터와 같은 사이즈의 행렬이며 다음 시점의 모델에 입력입니다.
#### 어텐션 매커니즘의 Q, K, V 벡터의 정성적인 의미를 설명하라.
* Q는 현재 단어가 필요로 하는 정보에 대한 representation 입니다. 그리고 K와 V는 입력 시퀀스의 각 단어에 대한 특징으로 보통 같은 값을 사용하지만 용도가 다릅니다. K는 어텐션 스코어 계산에 사용되며 V는 컨텍스트 벡터 계산에 사용됩니다.
* 어텐션 스코어는 현재 단어의 Q와 각 단어 K의 유사도를 의미하며 어텐션 웨이트는 현재 단어에 대한 각 단어의 중요도를 의미합니다.
* 컨텍스트 벡터는 현재 시점에서 각 단어 간의 중요도에 대한 요약을 의미합니다.
#### 인코더 셀프 어텐션과 디코더 셀프 어텐션의 차이를 설명하라
* 인코더 셀프 어텐션은 모든 단어를 사용할 수 있지만 디코더 셀프 어텐션은 마스킹 때문에 현재 위치 까지의 단어만 사용할 수 있습니다. 또한 인코더-디코더 어텐션의 경우 인코더 셀프 어텐션의 결과를 Q로 디코더 셀프 어텐션의 결과를 K, V로 사용합니다.
#### BERT와 GPT의 차이점을 설명하라
* BERT는 양방향 인코더 기반으로 입력 시퀀스의 모든 토큰을 사용할 수 있고 Masked Language Model 과 Next Sentence Prediction으로 학습합니다. 반면에 GPT는 단방향 디코더 기반으로 현재 위치 까지의 단어만 사용할 수 있고 다음 단어를 예측하는 task로 학습합니다. BERT는 문장을 이해하거나 분류하는데 강점을 보이고 GPT는 텍스트 생성에 강점을 보입니다.
#### 랭체인에 대하여 설명하라
* 랭체인은 LLM을 쉽고 효율적으로 사용할 수 있게 도와주는 프레임워크 입니다. GPT, 클로드 처럼 회사가 다른 여러 AI 모델을 API를 사용해 같이 사용할 수도 있고, 외부 데이터를 LLM에 쉽게 연결할 수도 있습니다.
#### RAG에 대하여 설명하라
* RAG는 Retrieval Augmented Generation으로 LLM이 답변할 때 외부 데이터베이스에서 관련 정보를 찾아와서 참고하면서 대답하는 방식입니다. 예를 들어, 회사 내부 문서를 참고해서 답변하는 것입니다. 최신 정보를 사용할 수 있는 장점과 출처가 있기 때문에 할루시네이션이 적은 장점이 있습니다.
* 문제점은 우리가 사용하는 PDF, 워드, 엑셀 같은 문서들이 출판용 구조이거나 테이블로 되어 있어 파싱 문제로 잘 작동하지 않습니다.
* 해결하기 위해 전처리와 텍스트 추출을 하는 것이 필요합니다.
#### ToD에 대하여 설명하라
* ToD는 Task-oriented Dialogue로 특정 목적을 달성하기 위한 대화 시스템입니다. 예를 들어, 식당 예약 같은 구체적인 작업을 완료하기 위한 대화 태스크 입니다. NLU, DST, DP, NLG 4가지 모듈로 구성되어 있습니다.
#### ResNet의 핵심 개념을 설명하라
* residual connection을 통해 더 깊은 층으로 구성된 모델도 학습이 가능합니다. 이전 블럭의 결과를 이번 블럭의 결과에 더해주는 구조로 gradiant vanishing 문제를 해결하고 깊은 층의 레이어도 학습할 수 있습니다.
#### CNN과 ViT의 차이를 설명하라
* 두 모델 모두 특징 추출을 하는 모델이지만 추출 매커니즘에 차이가 있습니다. CNN은 로컬 픽셀들 간의 관계에서 패턴을 찾고 ViT는 이미지 패치들 간의 관계에서 패턴을 찾습니다. CNN은 부분적 특징을 추출하는데 강점을 보이고 ViT는 전역적 관계를 추출하는데 강점을 보입니다.
#### 딥러닝 이전에 detection에 사용했던 방법을 설명하라
* 이미지의 경계와 방향을 분석하는 HOG와 이미지의 밝기 차이를 특정하여 눈코입의 패턴을 감지하는 Haar와 같은 방법이 있습니다.
#### Faster R-CNN의 장단점을 설명하라
* 장점으로 RPN (Region Proposal Network)을 사용한 ROI (Region of Interest) 자동 생성으로 속도가 빠르고 ROI 풀링과 ResNet 백본의 영향으로 정확도가 높습니다.
* 단점으로 네트워크가 2단계로 진행되어 실시간 처리가 어렵고 모듈수가 많아 구조가 복잡합니다.
#### YOLO의 장단점을 설명하라
* 장점으로 실시간 처리가 가능할 정도로 빠르고 end-to-end CNN 형태로 구조가 간단합니다.
* 단점으로 격자 기반 예측 방식으로 인해 작은 크기의 객체 검출 성능이 낮고 속도에 중점을 뒀기 때문에 상대적으로 정확도가 낮습니다.
#### 가장 선호하는 객체인식 알고리즘을 설명하고 장단점을 설명하라
* YOLO 입니다. 실시간 처리가 가능하며 end-to-end 모델이라는 점이 제가 추구하는 방향이랑 동일하기 때문입니다.
#### avg pooling과 max pooling의 차이를 설명하라
* 풀링 레이어는 입력 데이터의 크기를 줄이면서 중요한 특징을 추출합니다.
* avg pooling은 영역 내 모든 값의 평균을 취해 전반적인 특징을 보존하고 max pooling은 영역 내 최댓값만 선택해 가장 두드러진 특징만 유지합니다. 일반적으로 max pooling을 더 많이 사용합니다.
#### softmax 함수에 대하여 설명하라
* 여러 클래스의 점수를 확률로 변환하는 함수 입니다. 모든 출력값의 합이 1이 되도록 normalization 해줍니다.
#### semantic segmentation을 설명하라
* 이미지의 각 픽셀을 특정 클래스로 분류하는 작업 입니다. 대표적인 모델으로 FCN, U-Net이 있습니다.
#### CNN이 MLP보다 좋은 이유는 무엇인가
* CNN은 필터를 사용하는데 이는 곧 파라미터를 공유하는 것으로 메모리를 효율적으로 사용할 수 있고 주변 픽셀과의 관계를 학습할 수 있습니다.
#### CNN의 파라미터 수를 계산하는 방법을 설명하라
* (커널 크기 * 커널 크기 * 입력 채널 * 출력 채널) + 출력 채널 입니다.
#### 볼츠만 머신을 설명하라
* 현재 딥러닝 네트워크의 전신인 restricted 볼츠만 머신은 가시층과 은닉층으로 구성되어 있습니다. 각 층의 노드들은 확률적 상태를 가지며 실제값과 재구성값의 차이를 가중치 업데이트에 활용합니다. 역전파 알고리즘 없이 학습하는 초기의 딥러닝 알고리즘 입니다. 이 RBM이 곧 FC layer와 동일한 구조를 가집니다.
#### 오토인코더를 설명하라
* 입력을 압축했다가 복원하는 비지도학습 모델입니다. 인코더는 입력을 저차원으로 점차 압축하고 디코더는 압축된 정보를 원본 차원으로 점차 복원합니다.
<br><br>

### [머신러닝]
#### 머신러닝이란 무엇인가
* 데이터에서 패턴을 학습하여 새로운 데이터에 대한 예측을 하는 알고리즘을 말합니다.
#### 머신러닝의 학습법 종류를 설명하라
* 지도학습, 비지도학습 등이 있습니다. 정답이 있는 데이터로 학습하는 지도학습의 종류로 분류와 회귀가 있습니다. 정답 없이 데이터의 패턴을 발견하는 비지도학습의 종류로 군집화와 차원축소가 있습니다. 이외에도 강화학습, 자기지도학습 등이 있습니다.
#### precision, recall 공식과 개념을 설명하라
* 프리시전은 양성으로 예측한 것 중에 실제 양성인 비율으로 TP/(TP+FP) 입니다. 리콜은 실제 양성 중에 양성이라 예측한 비율으로 TP/(TP+FN) 입니다.
#### precision, recall의 중요성과 trade-off의 본질은 무엇인가
* 정성적인 의미로 프리시전은 불량이 아닌 것도 얼마나 과하게 검출을 했는가를 평가하는 것이고, 리콜은 불량인 것들 중에서 몇개를 놓쳤는가를 평가하는 것입니다.
* 모델을 어떤 각도로 평가하는지에 따라 중요성이 달라지며 동일한 성능이라고할 때 하나를 높이면 하나는 내려갈 수 밖에 없습니다. 예를들어 모델의 성능은 같은데 불량을 놓치지 않고 싶다면 과하게 검사할 수 밖에 없는 것입니다.
#### F1 공식과 의미를 설명하라
* 2*(프리시전*리콜)/(프리시전+리콜)으로 두 값의 조화평균 입니다. 둘 사이의 균형을 평가하는 지표 입니다.
#### 선형 회귀의 기본 가정은 무엇인가
* 선형 회귀는 선형성, 독립성, 등분산성, 정규성을 가정합니다.
* 선형성(독립 변수와 종속 변수의 선형관계), 독립성(오차들이 서로 독립), 등분산성(오차의 분산이 일정), 정규성(오차가 정규분포를 따름)
* (y = w1x1 + w0 + c에서 c가 오차. 얼마나 설명하지 못했는지를 나타냄.)
#### KNN과 K-means에 대하여 설명하라
* KNN은 해당 데이터의 K개 이웃의 다수결에 의해 분류하는 지도학습이고, K-means는 랜덤으로 클러스터 중심을 정하고 클러스터에 속한 샘플의 평균값으로 중심을 변경하며 최적의 군집을 찾는 비지도학습 입니다.
#### 데이터 샘플링을 설명하라
* 데이터의 일부를 추출하여 분석이나 학습에 사용하는 것 입니다.
* 무작위로 선택하는 random 샘플링, 종속변수의 클래스 비율을 유지하는 stratify 샘플링, 복원추출 방식을 사용하는 부트스트랩 샘플링 등이 있습니다.
#### 부트스트랩 샘플링에 대하여 설명하라
* 데이터를 샘플링하고 다시 되돌려 놓는 복원추출 방식으로 여러 개의 데이터셋을 생성하는 방법입니다.
#### 앙상블 학습에 대하여 설명하라
* 서로 다른 모델의 투표 결과로 예측하는 보팅, 하나의 모델을 부트스트랩 샘플링한 데이터에 대하여 학습하고 결과를 집계한 배깅, 서로 다른 모델을 부트스트랩 샘플링한 데이터에 대하여 학습하고 결과를 집계한 스태킹, 여러개의 클래시파이어가 가중치를 전달하며 순차적으로 학습하는 부스팅이 있습니다.
#### PCA가 무엇이고 언제 사용하는가
* 분산을 최대한 보존하면서(데이터의 특징을 잘 설명하면서) 직교하는 새로운 축을 찾아 투영하는 방식으로 차원을 축소하는 기법입니다. 차원을 축소하고 데이터를 압축할 때 사용합니다.
#### RMSE, MSE, MAE의 수식과 차이점을 설명하라
* MSE는 오차의 제곱의 평균이고 RMSE는 MSE의 제곱근 입니다. MAE는 오차의 절대값의 평균입니다. 제곱이나 평균은 부호를 제거하기 위해서 사용하고 루트는 제곱이 실제값과 크기가 달라지기 때문에 사용합니다.
#### CE에 대하여 설명하라
* (원핫 인코딩된 실제값) * 로그 (예측 확률)을 모두 더한 값으로 예측 확률 분포와 실제 정답 분포 간의 차이를 계산합니다.
#### Markov Chain을 설명하라
* 현재 상태가 이전 상태에만 의존하는 확률 과정입니다. 다음 상태는 오직 현재 상태에만 영향을 받으며, 과거 상태들은 고려하지 않습니다. 날씨 예측이나 주가 예측 등에 활용됩니다.
#### SVM에 대하여 설명하라
* 두 클래스 간의 경계를 찾는 알고리즘으로 마진을 최대화하는 초평면을 찾는 것을 objective로 하는 알고리즘 입니다.
#### SVM은 왜 반대로 차원을 확장시키는 방법을 사용하는지 설명하라
* 저차원에서 선형 분리가 불가능한 데이터를 고차원으로 매핑하면 선형 분리가 가능한데 이를 커널 트릭이라고 합니다. 이렇게 프로젝션과 연산으로 두단계로 한다면 계산량이 늘어나지만 내적을 활용하면 한번에 효율적으로 계산할 수 있습니다.
#### 회귀와 분류에 알맞은 matric을 선택하고 설명하라
* 회귀는 큰 오차가 있을 경우 MSE가 적절하고 이상치가 있을 경우 MAE가 적절합니다.
* 분류는 accuracy가 보편적으로 좋지만 데이터 불균형이 있을 경우 F1이 적절합니다.
#### 인공신경망이 가지는 문제점을 설명하라
* 학습 데이터의 양이 많아야하고 학습에 많은 양의 컴퓨팅 리소스를 필요로 합니다. 또한 블랙박스로 모델 해석이 어렵습니다.
#### ROC 커브에 대하여 설명하라
* 이진 분류기의 성능을 시각화하는 그래프입니다. x축은 FP rate, y축은 TP rate를 나타냅니다. 곡선 아래 면적이 클수록 좋은 성능을 의미합니다.
#### 서버가 100개 있을 때 인공신경망보다 랜덤포레스트를 선택해야 하는가
* 랜덤포레스트가 더 적합합니다. 각 트리를 독립적으로 학습할 수 있어 병렬 처리가 자연스럽고, 서버 간 통신 부하가 적습니다. 반면 신경망은 파라미터 동기화가 필요해 분산 학습 시 통신 부하가 크고, 학습 안정성도 떨어질 수 있습니다.
#### cross validation에 대하여 설명하라
* 전체 데이터를 k개의 폴드로 나누어 k-1개로 학습하고 1개로 검증하는 과정을 k번 반복하는 방법입니다. 과적합을 방지하고 모델의 일반화 성능을 평가하는데 유용합니다.
#### gradient boosting에 대하여 설명하라
* 여러개의 디시전 트리를 순차적으로 학습하는 앙상블 기법입니다. 각 단계에서 이전 모델이 만든 오차를 줄이기 위해 그라디언트를 계산하고 이를 보정하는 방식으로 새 모델을 추가합니다.
#### XGBoost에 대하여 설명하라
* 그라디언트 부스팅의 계산 효율성과 과적합 방지를 개선한 모델입니다. 병렬 처리와 분산 학습이 가능하고 정규화 기법을 포함하고 있습니다.
#### LightGBM에 대하여 설명하라
* 그라디언트 부스팅의 속도와 메모리 사용량을 개선한 모델입니다. leaf-wise 방식으로 트리를 생성해 더 깊은 노드까지 효율적으로 학습하고 카테고리컬 데이터를 인코딩 없이 직접 사용할 수 있습니다.
#### 좋은 모델이란 무엇인가
* 좋은 모델은 과적합 되지 않고 잘 일반화되며 설명이 가능하고 안정적으로 잘 작동하는 모델입니다. 단순히 학습 데이터에서만 성능이 좋은 것이 아니라 실제 문제 해결에 도움이 되어야 합니다.
#### 하이퍼 파라미터 최적화 방법을 설명하라
* 모든 조합을 시도하는 그리드 서치, 레인지 안의 무작위 값을 선택하는 랜덤 서치, 이전 시도 결과를 바탕으로 최적 값을 예측하며 탐색하는 베이지안 옵티마이저 등이 있습니다.
#### feature selection의 목적과 방법을 설명하라
* 과적합을 방지하고 계산 비용을 줄이기 위함입니다. filter 방법으로 상관계수가 높으면 소거할 수 있고, wrapper 방법으로 성능을 보고 선택할 수 있고, embedded 방법으로 학습 과정에서 소거하여 선택할 수 있습니다.
#### 데이터 불균형이 무엇이고 해결하는 방법을 설명하라
* 특정 클래스의 데이터가 다른 클래스에 비해 매우 적은 상황으로 오버피팅이나 언더피팅을 유발합니다. 오버샘플링, 언더샘플링, 클래스 가중치 설정 등을 통해서 해결할 수 있습니다.
#### 다중공산성을 설명하고 문제가되는 이유는 무엇인지 설명하라
* feature들 간에 강한 상관관계가 있는 현상입니다. feature를 많이 사용하더라도 대부분 같은 의미를 설명하기 때문에 소용이 없게 됩니다. 따라서 성능이 낮게 나올 가능성이 큽니다.
#### 차원의 저주에 대하여 설명하라
* 고차원의 데이터에서 차원이 증가할수록 학습에 필요한 데이터의 양이 기하급수적으로 증가하는 현상입니다. 거리 기반 알고리즘의 성능이 저하되고 데이터 밀도가 희박해져 과적합될 가능성이 큽니다. 따라서 차원축소가 필요합니다.
<br><br>

### [통계학]
#### 편향과 분산에 대하여 각각 설명하라
* bias는 예측값이 실제값과 얼마나 다른지를 나타냅니다. variance는 데이터의 변화에 따라 모델의 예측이 얼마나 달라지는지를 나타냅니다. 예를들어 bias가 높고 variance가 낮은 모델은 탄착군은 형성되지만 중심을 못맞추는 사수라고 볼 수 있고 variance가 높고 bias가 낮은 모델은 중심 근처를 맞추지만 넓게 퍼진 형태로 쏘는 사수라고 볼 수 있습니다.
#### p-value를 모르는 사람에게 설명하라
* 가정한 결과가 우연히 나올 확률 입니다. 예를 들어 p-value가 0.05라면 이런 결과가 우연히 나올 확률이 5%밖에 안 된다는 의미로, 결과가 통계적으로 의미있다고 볼 수 있습니다.
#### R^2의 의미는 무엇인가
* 모델이 데이터의 변동을 얼마나 잘 설명하는지를 나타내는 지표입니다. 0~1 사이의 값을 가지며, 일반적으로 0.64가 넘으면 모델의 설명력이 좋다고 판단합니다. 결정계수는 상관계수의 제곱값으로 계산할 수 있습니다.
#### 평균과 중앙값의 차이와 사용 예시를 설명하라
* 모든 값의 합을 개수로 나눈 값으로 이상치에 민감합니다. 반면에 중앙값은 데이터를 정렬했을 때 가운데 있는 값으로 이상치의 영향이 적습니다.
#### 중심극한정리를 설명하라
* 표본의 크기가 충분히 크면, 표본평균의 분포는 정규분포에 가까워진다는 이론입니다. 이는 모집단의 분포와 관계없이 성립합니다.
#### 엔트로피와 information gain을 설명하라
* 엔트로피는 데이터의 불확실성을 측정하는 지표이고 information gain은 특정 특성으로 분할했을 때 줄어드는 엔트로피의 양입니다. 디시전 트리에서 사용합니다.
#### probability와 likelyhood의 차이를 설명하라
* probability는 주어진 모수에서 특정 데이터가 관찰될 확률이고 likelyhood는 관찰된 데이터가 주어졌을 때 특정 모수가 맞을 가능성입니다.
* probability는 공정하다는 것을 가정하고 미래의 결과를 예측하는 것이고 likelyhood는 이미 결과를 관찰한 뒤 동전이 공정할 가능성을 평가합니다.
#### 베이지안과 프리퀀티스트의 차이를 설명하고 본인의 의견을 설명하라
* 베이지안은 사전지식을 활용하고 확률을 확률변수로 보며, 프리퀀티스트는 확률을 장기적인 빈도로 해석하고 확률를 고정된 값으로 봅니다.
* 베이지안의 입장에서 확률은 불확실성이 있고 계속 변하는 것이고 프리퀀티스트의 입장에서 확률은 이미 많은 데이터에 의해 결정된 것 입니다.
* 저는 프리퀀티스트 입니다. 통계적 검정인 p-value 0.05, 상관계수 0.8 등을 활용하는 편이고 데이터는 객관적이고 진실을 반영하며 데이터에 의한 의사결정을 추구하기 때문입니다.
#### missing value가 있을 경우 채워넣을 것인가
* 데이터가 랜덤하게 없을 경우 평균값이나 중앙값으로 대체할 것이고 특정한 패턴이 발견될 경우 그 자체로 의미있는 정보일 가능성이 있으므로 별도로 처리할 것입니다.
#### 아웃라이어를 판단하는 기준은 무엇인가
* 통계적으로 Q1 - 1.5xIQR 과 Q3 + 1.5xIQR을 넘어간 값이고 z-score 관점에서 평균으로부터 3시그마를 벗어난 값으로 볼 수 있습니다.
#### 동전을 10번 던졌는데 앞면이 1번 나왔다. 공정성 테스트를 위한 귀무가설과 p값은 무엇인가
* 귀무가설은 동전이 공정하다로 앞면이 나올 확률이 0.5인 것입니다. p값은 이항 분포 B(10, 0.5)에서 1번 이하로 나올 확률이므로 p값은 (1+10)/1024 = 0.011 정도 입니다. 유의수준 0.05에서 귀무가설을 기각하므로 동전은 불공정합니다.
#### 1000번 동전을 던졌을 때 550번 앞면이 나왔다. 동전은 편향되었는가
* 귀무가설은 동전이 공정하다로 앞면이 나올 확률이 0.5인 것입니다. 표준정규분포로 근사하면 n=1000, p=0.5 이므로 평균은 np로 500 입니다. 시그마는 루트np(1-p) 이므로 루트 250 이므로 16정도 입니다. 중심으로부터 벗어난 거리 50을 시그마로 나누면 z score가 3이 넘으므로 동전은 공정하지 않습니다.
#### 4보다 큰 숫자가 나올 때까지 주사위를 연속으로 굴렸는데 4번째에서 나오는 확률은 얼마인가
* 한번에 성공할 확률은 2/6으로 1/3 입니다. 3번 모두 실패할 확률은 (2/3)^3 이므로 8/27 이고 마지막에 성공할 확률 1/3을 곱하면 8/81으로 약 0.1 입니다. 따라서 1-0.1=0.9 입니다.
#### 주사위가 두번 연속으로 5가 나올때까지 굴릴 때 예상되는 굴리는 횟수
* 한번에 성공할 확률은 (1/6)^2로 1/36 입니다. 따라서 예상 횟수는 1/p로 36회 입니다.
#### 두 게임 중에 무엇이 더 유리한가. 게임1: 한번에 두개 주사위를 던져 두 값의 곱에 해당하는 달러를 가진다. 게임2: 하나의 주사위를 던져 값의 제곱에 해당하는 달러를 가진다.
* 주사위의 모든 눈 수의 합은 7*3인 21이고 면이 6개 이므로 기댓값은 21/6=7/2 입니다. 게임 1은 기댓값 두개를 곱하는 것이므로 약 49/4=12 입니다. 게임 2는 1+4+9+...+36=91에 6을 나눈 값으로 약 91/6=15 입니다. 따라서 게임2가 더 유리합니다.
#### 사용자의 80%가 60%의 영화에 좋아요를 누르고 사용자의 20%는 모든 영화에 좋아요를 누르는 'lazy user'이다. 누군가 연속으로 3개 영화에 좋아요를 눌렀다면 'lazy user'일 확률은 얼마나 되는가
* 베이즈 정리를 사용하여 계산합니다. P(lazy)=0.2, P(3likes|lazy)=1, P(3likes|unlazy)=0.6^3=0.2 입니다. 
* P(lazy|3likes) = P(3likes|lazy)*P(lazy)/P(3likes) 이므로 P(3likes)를 구해야합니다.
* P(3likes) = P(3likes|lazy)*P(lazy) + P(3likes|unlazy)*P(unlazy)로 구할 수 있습니다.
#### 아이겐벡터와 아이겐벨류가 무엇이고 왜 중요한가
* 아이겐벡터는 선형변환 후에도 방향이 유지되는 벡터이고 아이겐벨류는 해당 벡터의 스케일 변화량 입니다. 차원축소 알고리즘에서 활용할 수 있고 복잡한 선형 변환을 간소화시켜주기 때문에 중요합니다.
#### 상관관계와 인과관계의 차이점을 설명하라
* 상관관계는 두 변수 간의 통계적 연관성이 있다는 것으로 선형이나 비선형관계가 있다는 것 입니다. 인과관계는 긴밀한 원인 결과 관계가 있다는 것으로 한 변수가 다른 변수에 직접적인 영향을 준다는 것 입니다.
#### 연역적 논리와 귀납적 논리의 차이점을 설명하라
* 연역적 논리는 디덕션으로 일반적인 규칙에서 결론을 도출하는 것이고 귀납적 논리는 인덕션으로 사례에서 일반적인 규칙을 도출하는 것입니다. 대표적인 예시로 디덕션에는 삼단논법이 있으며 인덕션에는 머신러닝이 있습니다.
<br><br>

### [데이터분석]
#### AB 테스트에 대하여 설명하라
* 두 가지 버전(A와 B)을 무작위로 사용자에게 보여주고 어떤 버전이 더 효과적인지 통계적 유의성을 검증하여 의사결정에 활용하는 방법입니다.
#### EDA가 중요한 이유를 설명하라
* 데이터의 특성, 패턴, 이상치를 파악하여 더 나은 의사결정을 할 수 있게 해주기 때문입니다. 데이터 전처리 방향과 분석 방법을 선택하는 데 도움을 줍니다.
#### 좋은 feature란 무엇이고 판단하는 방법을 설명하라
* 좋은 feature는 타겟 변수와 높은 상관관계가 있고, 다른 feature들과는 낮은 상관관계를 가지는 feature 입니다.
#### NoSQL과 RDBMS의 차이점을 설명하라
* NoSQL은 유연한 스키마를 가지고 있어 대용량 데이터 처리에 적합하며 수평적 확장이 용이합니다. (=몽고DB, 카산드라) RDBMS는 정형화된 스키마와 관계를 중시하며, 데이터 일관성을 보장합니다. (=MySQL)
#### window 함수에 대하여 설명하라
* 행과 행 간의 관계를 정의하여 연산하는 함수입니다. 랭킹 함수, 집계 함수 등이 있으며 partition by로 그룹을 나누고 order by로 정렬을 할 수 있습니다.
#### MySQL에 대량의 데이터를 insert 하는 방법을 설명하라
* LOAD DATA INFILE을 사용하여 csv 파일을 로드하거나 여러 insert를 하나의 트랜잭션으로 묶어서 처리하면 됩니다.
#### 쿼리 성능을 확인하는 쿼리문은 무엇인가
* SHOW PROFILE을 사용해 쿼리의 실행 시간과 리소스 사용량을 확인할 수 있습니다. EXPLAIN을 사용하면 실행 계획을 자세하게 볼 수 있습니다.
#### MySQL이 느릴 때 가장 먼저 보는 것인 무엇인가
* slow_query_log 설정을 켜서 넥이 되는 쿼리를 확인합니다. 또한 EXPLAIN으로 쿼리의 성능을 확인하고 CPU나 메모리의 상태를 확인합니다.
#### 동작하고 있는 MySQL을 백업하는 방법은 무엇인가
* DB가 작을 경우 논리적 백업으로 mysqldump를 하고 DB가 클 경우 물리적 백업으로 XtraBackup를 사용하면 됩니다.
#### Tableau를 사용하는 이유를 설명하라
* 대시보드 제작이 쉽고 빠르기 때문입니다. 상호작용이 가능한 그래프를 그릴 수 있고 실시간으로 데이터를 업데이트할 수 있는 장점이 있습니다.
#### 4가지 이상의 정보를 시각화하는 방법을 설명하라
* 다차원 플랏을 설계하면 됩니다. 예를들어 뒤에 낮은 투명도로 막대 그래프를 그리고 위에 산점도 그래프를 그립니다. 산점도의 모양, 크기, 색깔을 통해서 차원을 더 추가할 수 있습니다.
#### 파이차트가 좋지 않은 이유를 설명하라
* 각도나 면적 비교가 어려워서 정확한 비교가 어렵습니다. 특히 비슷한 크기의 조각이 있으면 정확한 숫자를 표시해야 누가 더 큰지 알 수 있습니다.
#### hadoop과 spark의 차이를 설명하라
* 하둡은 디스크 기반이고 스파크는 메모리기반 입니다. 그래서 스파크는 속도가 더 빠르고 실시간 처리가 가능하고 하둡은 배치 처리에 특화되어 있습니다.
#### MapReduce에 대하여 설명하라
* 대용량 데이터 처리를 위한 분산 프로그래밍 모델입니다. 키-벨류 쌍을 생성하는 맵 단계, 맵 단계의 중간 결과를 전송하는 셔플 단계, 그룹화된 데이터를 처리해 최종 결과를 계산하는 리듀스 단계로 진행됩니다.
#### 잘 만들어지는 MapReduce는 무엇인가
* 특정 파티션이나 키에 집중되는 데이터 스큐 현상이 없고 네트워크 부하를 발생시키는 셔플링이 최소화된 경우 입니다. 맵 단계에서 최대한 데이터를 필터링한 뒤에 최대한 작은 양의 데이터를 가지고 리듀스 작업을 하는 것이 좋습니다.
#### MapReduce 중간에 fail이 나는 것을 어떻게 모니터링 하는가
* YARN log -applicationId 나 JobTracker를 통해서 모니터링할 수 있습니다.
#### 분산환경의 join은 (디스크, CPU, 네트워크) 중 어디서 병목이 일어나고 해결방법은 무엇인가
* 주로 네트워크에서 병목현상이 발생합니다. 데이터 셔플링을 할 때 네트워크의 부하가 큽니다. 브로드캐스트 조인이나 버킷팅으로 개선할 수 있습니다.
#### 암달의 법칙을 설명하고 shared-nothing 구조를 설명하라
* 암달의 법칙은 병렬화로 얻을 수 있는 최대 성능 향상을 계산하는 법칙 입니다. shared-nothing 구조는 노드 간에 리소스를 공유하지 않는 아키텍처를 말하며 독립적인 리소스를 가지므로 네트워크 부하를 최소화 합니다.
#### shared-nothing의 장단점을 설명하라
* 장점은 확장성이 높고 리소스간에 경쟁이 발생하지 않는 것이고 단점은 데이터 정합성 관리가 어렵고 노드 간 통신에서 부하가 발생할 수 있는 것입니다.
#### 대용량 자료를 빠르게 lookup하기 위한 백엔드는 무엇인가
* Redis 같은 인메모리 DB가 좋습니다. 키-벨류 구조로 빠른 검색이 가능하기 때문입니다.
#### Apache 보다 Nginx가 성능이 좋은 이유를 설명하라
* 이벤트 기반 처리 방식으로 메모리를 적게 사용하고 동시 접속도 잘 처리하기 때문입니다. 아파치는 프로세스 기반이라 리소스를 많이 사용합니다.
#### node.js는 빠르지만 사용하면 안되는 경우를 설명하라
* node.js는 CPU 집약적 계산을 목적으로 만든 언어가 아니며 싱글 스레드이기 때문에 계산 시간이 오래걸리면 다른 요청이 모두 막히기 때문입니다.
<br><br>

### [알고리즘]
* 깃허브 코딩 인터뷰 유니브
* 깃허브 인터뷰 비기너
#### 파이썬 데코레이터, 제너레이터, 이터레이터의 개념과 사용 예시를 설명하라
#### 탐색의 방법은 무엇이 있고 각각의 시간 복잡도를 설명하라
#### 해시 알고리즘을 설명하라
<br><br>

### [자료구조]
#### 파이썬 리스트와 딕셔너리의 차이를 설명하라
<br><br>

### [컴퓨터과학]
#### 서버를 처음 사고 어떤 보안적 조치를 할지 설명하라
#### 동시에 10개 컴퓨터에 라이브러리를 설치하는 번거로움을 해결하는 방법
#### vim과 emacs 중에 어떤 것을 사용하는가
#### 가장 좋아하는 리눅스 배포판과 이유를 설명하라
#### 관리하는 서버가 10대가 넘었을 때 중요한 모니터링 지표는 무엇인가
<br><br>



## `[인성 면접]`
* 두괄식으로 말하기
* 내가 가진 경험, 역량, 소프트 스킬과 연계
* 경험 목록
    * 석사 논문의 딥러닝 설계
    * 멀티 GPU 리눅스 서버
    * 모델링 직무 준비 과정
    * LGD 애플워치 자동검사
    * 데이터분석 프로젝트
    * 논문 리뷰 블로그
* 역량 목록
    * AI 모델링
    * 도메인 지식 활용
    * AI 모델 숙련도
    * 수학적 이해와 통계적 지식
    * 논문 리서치
    * AI 모델 트렌드
* 소프트 스킬 목록
    * 문제해결력
    * 창의성
    * 커뮤니케이션
    * 스토리텔링
    * 자기주도적 성장 의지
<br><br>

### [필수]
#### 자기소개
* 안녕하십니까 트랜스포머 연구 경험을 가진 김가람 지원자 입니다. 저는 (직무명) 직무를 원활히 수행할 수 있는 2가지 역량을 가지고 있습니다.
* 첫째 (역량) 입니다. (짧은 설명), 둘째 (소프트 스킬) 입니다. (짧은 설명)
* 이러한 (역량)과 (소프트 스킬)를 바탕으로 정량적인 성과를 이끌어내는 (직무명)으로 성장하겠습니다.
#### 지원동기
* 평소 (도메인)에 대한 관심을 가지고 있었고, (직무에서 하는일) 경험을 통해 (직무명)에 대한 확신이 생겼기 때문에 지원하게 되었습니다.
* (도메인 관련 경험)을 통해 (도메인)에 관심이 있었고 (회사명)에서 제 역량을 발휘할 수 있다고 생각해 지원하게 되었습니다.
* (직무 관련 경험)을 통해 (직무명)에 대한 확신이 생겼습니다.
* 종합적으로 제가 가지고 있는 (도메인)에 대한 관심과 경험을 통해 쌓은 (직무에서 하는일) 역량을 발휘해 (회사명)과 함께 발전할 수 있다는 생각을 해서 지원하게 되었습니다.
#### 장단점
* 장점으로 (소프트 스킬1)을 가지고 있습니다. (짧은 설명) (예시) (업무 적용)
* 단점으로 (소프트 스킬2)를 가지고 있습니다. (짧은 설명) (극복 방법)
<br><br>

### [회사관심도]
#### 우리 회사를 어떤 회사로 알고 있고 왜 지원했는가
* (도메인)에서 (직무에서 하는일)을 잘 활용하는 혁신적인 회사로 알고 있습니다. 대표적인 서비스로 (서비스명)을 사용해봤습니다.
* (지원동기)
#### 본인 역량을 우리 도메인에 어떻게 사용할 수 있는가
* (역량, 소프트 스킬)을 바탕으로 (구체적인 방법론)으로 (서비스명)에 활용하겠습니다.
* (서비스명)은 (구체적인 원인) 때문에 (역량, 소프트 스킬)이 필수적입니다.
* 저는 (경험)을 통해서 (역량, 소프트 스킬)을 키워왔습니다.
#### 입사 시 하고싶은 일이 무엇인가
* (구체적인 서비스)에서 (구체적인 업무) 업무를 하고 싶습니다.
* (구체적인 업무)은 (구체적인 원인) 때문에 (역량, 소프트 스킬)이 필수적입니다.
* 저는 (경험)을 통해서 (역량, 소프트 스킬)을 키워왔습니다.
#### 입사 후 포부를 말하라
* 먼저 새로 들어온 구성원으로서 업무를 적극적으로 배우겠습니다. 뚜렷한 목표를 가지고 회사의 노하우가 담긴 (직무에서 하는일) 방법론을 이해하겠습니다.
* 더 나아가 현재보다 더 높은 수준의 AI 모델링 능력을 위해 꾸준히 최신 논문과 알고리즘을 공부하겠습니다.
* 최종적으로 (구체적인 업무) 업무에서 (회사명)에 큰 힘이 되도록 노력하겠습니다. (역량1)과 (역량2)를 최대한 발휘하여 정량적인 성과를 이끌어내도록 하겠습니다.
#### 마지막 한마디
* (회사명)와 함께 (회사 맞춤 혁신적인 서비스)를 꼭 해보고 싶습니다.
<br><br>

### [직무경험]
#### 직무 경험에 대하여 짧게 설명하라
* 요약 -> S(상황) -> T(과제) -> A(행동) -> R(성과)
    * 석사 논문의 딥러닝 설계
    * LGD 애플워치 자동검사
#### 직무 경험에 대하여 자세히 설명하라
* 요약 -> S(상황) -> T(과제) -> A(행동) -> R(성과)
    * 석사 논문의 딥러닝 설계
    * LGD 애플워치 자동검사
#### 직무에서 이루고자 하는 목표는 무엇인가
* AI를 통해 실질적인 비즈니스 가치를 창출하는 것입니다. AI는 정말 유용한 도구이지만 아직 큰 돈을 벌거나 혁신적인 서비스를 만들어낸 기업이 많지 않다고 생각합니다. AI를 활용해서 금전적 가치와 공익적 가치를 창출해서 모범사례가 되고 싶습니다. 일하는 사람의 능력에 대한 가치를 평가한 것이 연봉인 것처럼 회사의 성장 가능성이나 지금 가지고 있는 능력에 대한 가치를 평가한 것이 투자금과 주가라고 생각합니다. 그래서 항상 금전적인 가치로 증명을 해야한다고 생각해서 금전적인 가치와 공익적 가치를 모두 창출하는 것이 목표입니다. 그리고 이 과정에서 회사와 제가 같이 큰 성장을 할 수 있다고 생각합니다.
#### 최근 가장 인상적으로 읽은 논문은 무엇인가
* I-JEPA 입니다. 이 모델은 2023년에 얀르쿤 교수님 연구진이 발표한 자기지도학습 모델입니다. 기존 마스킹 기반 모델과 달리 latent representation을 예측하는 방식을 사용했는데 픽셀을 복원할 필요 없이 representation 그대로를 예측하자는 간단하면서 임팩트 있는 아이디어가 인상적이었습니다.
<br><br>

### [프로젝트]
#### 이 알고리즘을 사용한 이유는 무엇인가
* 답변 가능
#### 다른 유사한 알고리즘을 알고 있는가
* 답변 가능
#### 이 알고리즘의 단점은 무엇인가
* 답변 가능
#### 주요 역할과 배운점은 무엇인가
* (암기) 답변 가능
#### 프로젝트를 다시 진행한다면 어떻게 할 것인가
* 추후에 알게된 개선할 수 있는 메서드 적용
<br><br>

### [압박]
#### 본인은 전공자가 아닌데 왜 이 직무를 지원하는가
* AI를 통해 실제 문제를 해결하는 과정에 매력을 느껴 이 직무를 선택했습니다.
* LGD에서 머신러닝 알고리즘을 실제 문제에 처음 적용해봤고 이때 정말 재밌게 열정을 가지고 일했습니다. 이 과정에서 AI 모델링 역량이 필요하다고 생각했고 대학원에 진학했습니다. 석사 논문의 딥러닝 설계에서 분야의 SOTA를 달성했고 이때 직무에 대한 확신이 들었습니다.
* AI는 아직도 저에게 가슴뛰고 흥미로운 분야입니다. 일을 하면서 즐겁고 행복한 분야를 하기 위해서 선택하게 되었습니다.
#### 본인은 이 직무를 위해 어떤 준비를 해왔는가
* 먼저 (직무명)이 되기 위해 어떤 역량이 필요한지 탐색하여 달성해야하는 목표를 세웠고 하나하나 달성 해왔습니다.
* 컴퓨터공학 기초, 파이썬, SQL 역량을 위해 비트캠프라는 학원에서 5개월간 대면 강의를 들었고, AI 모델링을 위해 석사 학위를 따며 연구를 했고, 통계와 데이터 사이언스 역량을 위해 ADsP 자격증을 취득했고, Spark, 태블로, 데이터 분석 역량을 위해 제로베이스라는 학원에서 4개월간 강의 수강과 프로젝트를 진행했습니다.
* 저는 이 직무를 목표로 자기주도적으로 강한 성장 의지를 가지고 준비해왔습니다.
#### 본인은 분석가 인재인가 사이언티스트 인재인가
* 저는 (직무명) 인재입니다. (직무에서 하는 일) 역량을 더 중점적으로 개발해왔습니다.
#### 경쟁사를 지원했는가 왜 둘중에 우리 회사를 선택하는가
* (도메인) 관련 회사를 다양하게 지원한 상태지만, (회사명)이 가장 입사를 희망하는 곳입니다. 솔직히 지금 같은 취업대란에 최종합격이 안될 경우를 대비해야만 했습니다. 그러나 (회사명)에 합격되면 다른 회사는 과감히 포기하고 반드시 (회사명)에 입사할 생각입니다.
#### 다른 도메인의 회사도 지원했는가
* 지원하지 않았습니다. 일단 (도메인) 관련 회사들만 먼저 지원하고 만약에 취업이 잘 안될 경우 다른 도메인을 지원하는 것도 고려하고 있습니다.
#### 왜 박사를 하지 않았는가
* 연구도 좋지만 현업에서 실무를 뛰며 배우는 점이 많다고 생각합니다. 서로 상호보완적인 관계이며 박사를 하는 것도 좋은 선택일 수 있습니다. 하지만 저는 실제 서비스를 소비자들에게 제공하며 배우는 것을 선호합니다.
#### 희망하지 않는 업무를 준다면 어떻게 할 것인가
* 저는 (구체적인 업무명)에 대한 확고한 목표가 있기 때문에, 먼저 회사에 이 업무를 하고 싶다고 한번 말해볼 것 같습니다. 하지만 그래도 만약에 회사에서 다른 업무를 권유 한다면, 회사의 공동 목표와 성과를 위한 업무배치라고 생각하기 때문에 해당 업무에서 저의 역량을 최대한 발휘해서 일하도록 하겠습니다.
<br><br>

### [소프트스킬]
#### 가장 힘들었던 순간은 언제인가
* LG디스플레이에서 베트남 출장을 길게 갔을 때 입니다. 저는 이때 끈기와 긍정적인 자세로 도전하여 힘들었던 순간을 극복했습니다. 당시에는 코로나 때문에 길에서 돌아다닐 수도 없고 회사 호텔을 반복하는 일상이었습니다. 하지만 책임감을 가지고 있었기 때문에 프로젝트를 성공적으로 마무리 했습니다. 저는 이때 끈기 있게 도전한다면 뭐든지 할 수 있다는 자신감을 얻게 되었고, 아무리 막연하고 힘든 상황에서도 긍정적으로 다시 도전하는 습관을 가지게 되었습니다.
#### 리더 경험을 설명하라
* 알고리즘 엔지니어들, 역할분장, 문제 판단, 책임감 중요성, 구성원들을 한명한명 챙기는 꼼꼼함
#### 팔로워 경험을 설명허라
* 프로젝트 전반, 정확하게 수행, 리더에 비해 상대적으로 일이 적고 시야가 넓기 때문에 리더가 놓치는 부분을 파악
#### 존경인물이 누구인가
* ACDC의 보컬 브라이언 존슨 입니다. 고등학교 때도 활발히 밴드 활동을 하면서 마블의 영화 아이언맨의 OST Back in black로 ACDC를 처음 접했습니다. 다른 세션보다 철학적인 생각을 가진 그는 이런 말을 했습니다. Result. 그것을 밤낮으로 부단히 노력하는 걸음들의 by-product가 되게 하라. 꾸준한 노력을 통해 자연스럽게 결과물을 도출하라는 그의 가치관이 너무 멋있었고 저도 다가가는 분야에 부단한 노력을 하게 되었습니다. 그 이후로도 공부나 취미에 있어서 부단한 노력을 통해 성공했고, 가치관에 대한 확신이 쌓여 지금의 제 자세를 형성하게 되었습니다.
#### 가장 후회되는 일은 무엇인가
* 크게 인생에서 후회되는 기억은 많이 없습니다. 다만 대학교 1학년 2학년때 학교생활이 바빠서 부모님께 연락을 많이 못 드린 점이 항상 후회됩니다. 그 이후 부모님께 자주 연락도 드리고 집에도 내려가 지내고 있습니다.
#### 취미는 무엇인가
* 저의 취미는 클라이밍 입니다. 일이 잘 풀리지 않을 때 머리를 비우기 위해 클라이밍장에 갑니다. 공부나 업무에 스트레스를 받는 일이 생기면 운동으로 기분을 환기하고 다시 에너지 넘치게 복귀할 자신이 있습니다.
#### 주량은 어떻게 되는가
* 주량은 중간정도라고 생각합니다. 보통 술자리에서 소주 1병정도 마십니다.
#### 가족을 소개하라
* 저희 가족은 부모님과 형 그리고 제가 있습니다. 저희 부모님은 두 분 다 국어 교사로 재직하셨었고, 어릴 때부터 글쓰기와 메모하는 습관을 길러주셨습니다. 형은 저보다 4살 많고, 현재 공무원으로 일하고 있습니다.
#### 노조 문제에 대하여 어떻게 생각하는가
* 노조는 권익을 위해 필요하지만, 사내 정치 세력이 되어 회사 정책의 반대를 위한 반대만을 하거나, 회사는 생각지 않고 자신들만의 주장을 관철시키려는 것은 바람직하지 않다고 생각합니다. 근로자와 회사 모두에게 무익하다고 생각하기 때문입니다.
#### 상사와의 갈등이 생긴다면 어떻게 할 것인가
* 먼저 제가 변하려고 노력하겠습니다. 상대방의 입장에서 생각하고 갈등/마찰의 원인이 저의 어떤 점에서 기인하는지를 생각하겠습니다. 그런 후 대화를 하겠습니다. 상사에게 개인면담을 요청하여 제가 어떤 점을 개선해야 할지 여쭈어 보고 그대로 노력해보겠습니다.
#### 상사가 부당한 지시를 내린다면 어떻게 할 것인가
* 상사님이 법규나 회사 사규에 위배되는 (불법한) 지시인 경우, 확인한 후 정중히 거절하겠습니다. 그러나 단지 업무분장(자신이 맡은 업무역할)에 맞지 않거나 제가 일을 좀 더 해야 하는 (불합리한) 지시라면 묵묵히 따르겠습니다.
#### 회사일과 개인일이 충돌하면 어떻게 할 것인가
* 저는 회사일에 우선순위를 둘 것입니다. 회사일과 개인일이 동시에 겹친다면 회사일을 먼저 처리하겠습니다. 조직의 일원으로서 공과 사를 구분하고 조직의 목표와 가치에 우선순위를 두는 것은 당연하다고 생각합니다. 물론 가족이나 지인과의 관계도 중요하므로 회사의 급한 상황을 잘 설명하고 약속을 연기하거나 양해를 구하겠습니다.
<br><br>

### [역질문]
#### (능력있는 동료, 재밌는 주제, 돈이 되는 사업)
#### 팀의 규모와 구성은 어떻게 되나요?
#### 현재 진행되는 사업은 무엇이고 계획중인 신사업은 무엇인가요?
#### 직무에 도움이 될만한 공부 분야나 책이 있나요?
#### 제가 채용이 되든 안되든 늘 건강하시고 오늘도 행복한 하루 보내시기 바랍니다! 감사합니다!
<br><br>

### [구체화]
#### 자기소개_DS
* (직무명): 데이터 사이언티스트
* (직무에서 하는일): AI 모델링
* (역량): AI 모델링
    * (경험): 석사 논문의 딥러닝 설계
    * AI 논문을 읽고 연구하는 방법론을 이해했고, 기존 논문을 파이토치로 구현해보며 딥러닝 모델에 대한 이해도를 향상시켰습니다. 이러한 이해를 바탕으로 직소퍼즐 분야의 딥러닝 모델을 설계하여 최고 성능을 달성했고, 이 모델을 깃허브를 통해 배포한 경험이 있습니다.
* (소프트 스킬): 문제해결력
    * (경험): LGD
    * LG디스플레이에서 AI빅데이터 직무로 일하며 애플워치 검사 자동화 머신러닝 알고리즘을 직접 개발하고 운영해본 경험이 있습니다. 이 과정에서 발생하는 다양한 문제들을 끈기 있게 해결하며 알고리즘의 정확도를 개선한 경험이 있습니다.
#### 지원동기_DS
* (직무 관련 경험)
    * 또한 LG디스플레이에서 애플워치 자동화검사기의 알고리즘을 설계하는 과정에 AI에 대한 관심이 크게 생겼고 AI 모델링 역량 개발의 필요성을 느껴 대학원에 진학했습니다. 새로운 것을 배우고 도전하는 것에 거부감이 없을 뿐만 아니라 직무에 대한 강력한 목표와 성장 의지가 있었기 때문에 끈기있게 공부를 했습니다. 이때 다진 역량을 바탕으로 FCViT라는 직소퍼즐 모델을 설계하여 해당 task에서 SOTA를 달성했습니다. 이 경험을 통해 데이터 사이언티스트에 대한 확신이 생겼습니다.
#### 장단점_DS
* (장단점)
    * 장점으로 미루지 않는 성격을 가지고 있습니다. 저는 일이 미뤄지면 신경이 분산되는 느낌을 싫어해서 일을 당장 처리하는 성격입니다. 예를 들어 업무 회의가 끝나면 지치고 힘들지만, 데이터를 분석하기 좋게 가공하고 그래프까지는 그려놓습니다. 일을 미루지 않으면, 과거의 기억을 더듬느라 많은 시간을 낭비하지 않고 효율적으로 일을 처리할 수 있습니다. 이런 성격이 업무를 할 때도 장점으로 작용할 수 있을 것입니다.
    * 단점은 일에 대한 걱정이 많다는 것입니다. 휴식을 할 때에도 계속 일에 대한 걱정을 하는 편인데, 이를 정확하게 분리하기 위해서 집에 돌아가면 바로 간단한 운동인 턱걸이를 하고 샤워 후 명상을 하는 루틴을 가지고 있습니다. 이를 통해 일에서 벗어나 머리를 비우고 몸이 온전하게 충전될 수 있도록 하고 있습니다.
#### 직무경험_DS
* 요약 -> S(상황) -> T(과제) -> A(행동) -> R(성과)
* 석사 논문의 딥러닝 설계
    * 대학원에서 석사 논문으로 객체 인식 등에 활용하는 사전학습인 직소퍼즐 문제를 푸는 딥러닝 모델을 설계해봤고, 이때 논리적이고 창의적으로 기존 모델을 압도하는 성능을 달성한 경험이 있습니다.
    * 대학원에서 수십 편의 논문을 읽었습니다. 그 중에서 GPT와 BERT 논문을 읽으면서 느낀점은 학습하는 전략이 인간 어린이의 놀이와 비슷하다는 점이었습니다. 그리고 비전에서도 이런 방식으로 학습하는 경우가 있는지 찾아봤고 직소퍼즐을 학습한 딥러닝 모델이 패턴 인식과 공간 추론 능력이 뛰어나다는 것을 발견했습니다. 최종적으로 자기지도학습 분야의 뛰어난 논문인 MAE와 직소퍼즐 분야의 모델들을 참고해서 딥러닝 모델 설계를 시작하게 되었습니다.
    * 직소퍼즐 분야의 모델들은 9개로 구성된 쉬운 퍼즐도 풀지 못하는 수준이었고 이 마저도 알고리즘에 내포된 문제로 어려움을 겪고 있었습니다. 첫번째 문제는 기존 모델들은 학습전략으로 분류 알고리즘을 사용했는데 분류 알고리즘의 경우 가능한 모든 경우에 대한 확률을 계산해야 하는 것입니다. 따라서 퍼즐 조각이 4개일 때는 4!으로 24개 9개일 때는 9!으로 약 36만개의 확률을 계산해야하고 퍼즐조각이 늘어나면 기하급수적으로 모델 사이즈가 증가하는 문제가 있었습니다. 두번째 문제는 기존 모델들은 CNN 인코더를 사용하고 있었는데 CNN은 지역적 특징 추출 한계를 가지고 있는 것입니다. 즉 task에 적합하지 않은 인코더를 사용하고 있는 문제가 있었습니다.
    * 저는 간단하고 효과적인 아이디어로 두가지 문제를 해결했습니다. 첫번째로 학습전략을 분류 알고리즘에서 회귀 알고리즘으로 바꿨습니다. 이 작업은 말처럼 간단하지는 않습니다. 레이블을 만들어내는 알고리즘, 최종 레이어의 설계, loss function을 모두 바꿔야하기 때문입니다. 결론적으로 문제해결력을 발휘해 차근차근 해결했습니다. 순열 레이블을 수평수직 좌표 레이블로 바꾸고 최종 레이어와 loss function의 설계를 결정했습니다. 두번째로 CNN 인코더를 ViT로 대체했습니다. 기존 모델은 퍼즐을 조각낸 뒤 퍼즐 하나하나의 representation을 추출하고 concat하는 방식을 사용했습니다. 저는 이미지를 통째로 넣고 한번에 representation을 추출하도록 더 효율적인 구조를 설계했습니다.
    * 결론적으로 이미지넷 데이터셋 학습 및 평가에서 기존 모델을 7.3% 개선해 90.6%의 성능으로 SOTA를 달성했습니다. 논문은 저명한 저널에서 리뷰되고 있으며 깃허브에 모델 배포까지 완료했습니다. 프로젝트를 통해 알고리즘 문제를 논리적이고 창의적으로 해결하는 방법을 배웠습니다.
* LGD 애플워치 자동검사
    * LG디스플레이에서 AI빅데이터 직무로 일하며 애플워치 검사 자동화 알고리즘을 설계해봤고, 이때 문제해결력을 극한으로 개발한 경험이 있습니다.
    * 당시 회사에서는 저동화검사에 어려움을 겪고 있었습니다. 자동화검사는 품질관리, 성능, 속도 측면에서 사람보다 매우 우수하고 고객 측에서 요구한 사항이었습니다. 하지만 팀원들은 다양한 원인들로 여전히 해결하지 못하고 있었습니다.
    * 원인을 분석해보면 대부분의 선배들이 하드웨어 엔지니어로 feature engineering과 머신러닝을 적용하는 방법론에 대한 지식이 전혀 없었습니다. 그리고 같은 패널이라도 카메라 데이터가 일관성 없게 추출되고 있었습니다.
    * 저는 이런 문제들을 AI 스타트업 인턴 경험을 바탕으로 차근차근 해결했습니다. 불량품과 상관성이 높은 주요 feature를 추출했고 이를 바탕으로 머신러닝으로 rule extraction을 진행했습니다. 그리고 데이터의 신뢰도를 위해 평탄도, 포커스를 통계적인 방법으로 일관성 있게 유지했습니다. 뿐만 아니라, 창의적인 아이디어로 미사용 데이터를 발굴해 검출 불가 유형의 불량에 대한 알고리즘을 신규로 개발했습니다.
    * 결론적으로 불량 검출 알고리즘의 F1 score를 두자리수% 개선하여 품질을 개선했고 속도 개선과 캐파 상승으로 연간 수십억을 저감했습니다. 저는 이 프로젝트를 통해 문제해결력을 극한으로 개발했고 회사와 함께 성장한 경험이 있습니다.
#### 프로젝트_FCViT
* 알고리즘 장점
    * 효율성, 확장성 입니다.
* 알고리즘 단점
    * 회귀 알고리즘은 시각화가 힘듭니다.
* 다른 알고리즘
    * 위치를 예측하는 분류 알고리즘으로 할 수 있습니다.
    * 거리를 기반으로 하는게 인간과 유사하기 때문에 안했습니다.
* 주요 역할과 배운점
    * 역할: 딥러닝 모델 설계 학습 평가, 파이썬 구현, 학습 과정 시각화
    * 배운점: 논리적 창의적 해결, 하이퍼 파라미터 조절, 논문 핵심 요약 정리
* 다시 진행한다면
    * 파라미터나 아키텍처 테스트에서 여유를 두고 더 길게 학습하겠습니다.
#### 프로젝트_LGD
* 알고리즘 장점
    * 해석이 가능한 모델로 C레벨에 설명하기 편합니다.
* 알고리즘 단점
    * 유지보수가 까다롭습니다.
* 다른 알고리즘
    * 딥러닝 알고리즘으로 할 수 있습니다.
    * 딥러닝 모델링 능력이 부족해서 못했습니다.
* 주요 역할과 배운점
    * 역할: 검출 레시피 도출, 카메라 데이터 일관성 유지, 업체 유관부서 소통
    * 배운점: 문제해결력, 커뮤니케이션, 성과지향적 사고
* 다시 진행한다면
    * 딥러닝 해보고 싶습니다.
#### 프로젝트_은행
* 알고리즘 장점
    * 가볍고 빠릅니다.
* 알고리즘 단점
    * 효율성에 집중되어 있고 성능은 다른게 더 좋을 수 있습니다.
* 다른 알고리즘
    * TabNet과 XGBoost가 있습니다.
* 주요 역할과 배운점
    * 역할: 군집 추출, lightGBM 모델링, shaply value 사용 모델 해석
    * 배운점: 다차원을 고려한 플랏, lightGBM 특징과 파라미터, SHAP
* 다시 진행한다면
    * TabNet으로 GPU 사용해서 해보고 싶습니다.
#### 프로젝트_이커머스
* 알고리즘 장점
    * 복잡한 형태도 잘 작동합니다.
* 알고리즘 단점
    * 계산 비용이 크고 파라미터 수가 하나 뿐입니다.
* 다른 알고리즘
    * DBSCAN가 있습니다.
    * 군집화 하려는 데이터가 모여있지 않아 적합하지 않아서 안했습니다.
* 주요 역할과 배운점
    * 역할: 군집 모델링, 다중 차원 그래프 시각화, 성과지표 변화 추정
    * 배운점: 다차원을 고려한 플랏, DBSCAN과 GMM의 특징과 파라미터
* 다시 진행한다면
    * 다른 차원으로 projection하는 것을 시도해보고 싶습니다.
<br><br>


