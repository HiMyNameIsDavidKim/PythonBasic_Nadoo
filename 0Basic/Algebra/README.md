# Algebra

## `[대수학]`
* 미지수에 변수를 ‘대입’하는 기술, 그것을 ‘계산’하는 기술.
* 결론적으로 방정식을 푸는 기술.
* 코딩은 수학으로 되어 있는 것을 문자로 치환하는 것이므로 곧 대수학이다.
<br><br>

### [대수]
* 대수는 상수와 변수의 집합이다.
    * 상수 : constant, 변하지 않는 것
    * 변수 : variable, 변하는 것
* 대수학의 시작은 ‘알콰리즈미’에 의해 시작했고, 그 이름을 따 ‘알제브라’라고 명했다.
* 이에 파생되어 문제를 해결하는 솔루션을 '알고리즘'이라 한다.
<br><br>



## `[선형대수]`

### [행렬 기본]
* 전치 행렬 : transposed matrix, 주대각선을 축으로 하는 반사 대칭 행렬.
    * A^(T)
    * 주대각선 : main diagonal, i=j인 요소를 연결한 선.
    * (ex. [[a,a1,a2], [a1,b,a3], [a2,a3,c]])
    * 한 컬럼을 가진 행렬을 표현하기 위해 리스트의 전치행렬을 많이 쓴다.
* 행렬 곱 : matrix product, 두 행렬에서 한 행렬을 연산.
    * C = AB
    * C의 1,1 원소 = A의 1행과 B의 1열의 스칼라곱.
* 항등 행렬 : identity matrix, 주대각선의 원소가 모두 1이고 나머지는 0인 정사각 행렬.
    * I
    * 행렬A와 I를 곱셈하면 항상 A가 나온다.
* 역행렬 : inverse marix, 행렬과 곱한 결과가 단위행렬이 되게 하는 행렬.
    * A^(-1)
    * [[a, b], [c, d]]^(-1) = 1/(ad-bc)[[d, -b], [-c, a]]
* 행렬식 : determinant, 정사각 행렬에 스칼라를 대응시키는 함수의 하나.
    * det[[a, b], [c, d]] = ad - bc
* 선형 결합 : linear combination, 각 항에 상수를 곱하고 더함으로써 일련의 항으로 구성된 표현식.
    * x와 y의 선형결합은 ax + by 형식.
* 놈 : norms, 벡터의 크기를 측정하는 방법.
    * Ln = ∥x∥n
    * L1 = |x1| + |x2| + ... + |xn|
    * L2 = √ (x1^2 + x2^2 + ... + xn^2)
    * Lmax = 벡터 성분들 절대값 중에서 가장 큰 절대값.
    * L0 = 벡터 성분들 중에서 0이 아닌 값 개수.
<br><br>

### [행렬 심화]
* 고유벡터(x) : eigenvector, 선형 변환이 일어난 후에도 방향이 변하지 않는 0이 아닌 벡터.
    * 열벡터로 나타난다.
    * 정방행렬 A에 대하여 Ax = λx를 성립하는 x가 존재해야 한다.
* 고유값(λ) : eigenvalue, 선형 변환 후 달라진 배율값.
    * 상수로 나타난다.
    * 고유벡터에 대응한다.
* 켤레 전치 행렬 : 행렬을 전치한 후 모든 요소를 켤레 복소수로 바꾼 행렬.
    * A^(*)
* 에르미트 행렬 : 켤레 전치가 자기 자신과 같은 복소수 정사각 행렬.
    * A = A^(*)
    * (ex. [[2,2+i,4], [2-i,3,i], [4,-i,1]])
* 유니터리 행렬 : 켤레 전치가 역행렬과 같은 복소수 정사각 행렬.
    * A^(*) = A^(-1)
* 대각 합 : trace operator, 정사각 행렬의 주대각선 성분의 합.
    * Tr(A) = A_1,1 + A_2,2 + ... + A_n,n
<br><br>

### [행렬 분해]
* 고유값 분해 : eigen decomposition, 고유값 및 고유벡터 형태로 분해.
    * det(xI - A)로 고유벡터 x1, x2를 구한다.
    * 고유 벡터의 순서에서 고유행렬 P를 구한다.
    * P^(-1) A P = Λ에서 Λ를 구한다.
    * A = P Λ P^(-1) 이다.
    * 이때 P가 직교행렬 Q이면, A = Q Λ Q^(T)도 성립한다.
* 특이값 분해 : SVD(single value decomposition), 특정한 구조로 분해.
    * M = U Σ V^(*)
    * M = mxn 행렬
    * U = mxm 유니터리 행렬
    * V = nxn 유니터리 행렬
    * Σ = mxn의 주대각선 외 모든 요소가 0인 행렬.
<br><br>

### [무어-펜로즈 유사역행렬]
* 가역 행렬의 역행렬 연산을 일반화. 특이값 분해를 통해 계산한다.
* 즉, 역행렬이 있던 없던 강제로 역행렬을 뽑아낸다.
* A = U Σ V^(*)이 성립할 때, A^(+) = V Σ U^(*)
* 반드시 존재하며, 단 1개만 존재한다.
<br><br>

### [벡터 기본]
* 벡터의 정의
    * 물건을 운반하는 물체, 캐리어의 라틴어
    * 사물의 움직임을 표현하기 위한 가장 기본적인 구성요소
    * 크기와 방향을 모두 가지는 양
    * 크기만 가지는 것을 스칼라
* 벡터의 성질
    * 동등성
        * 크기와 방향만을 가진다.
        * 출발 지점은 아무 의미가 없다.
        * 출발 지점이 달라도 크기와 방향이 같으면 같은 벡터이다.
    * 영벡터
        * 크기가 0인 벡터를 영벡터라고 한다.
    * 음 벡터
        * 자신과 더했을 때 결과가 영벡터가 되는 벡터를 음벡터라 한다.
        * a의 음벡터는 -a라고 표시한다.
* 벡터의 성분
    * 벡터를 축에 projection하여 성분을 얻을 수 있다.
    * 성분 또한 벡터이므로 성분 벡터(component vector, a_x, a_y)라고 한다.
    * 2차원 공간에서 벡터는 2개의 성분 벡터를 가지고 a = a_x + a_y로 표시한다.
    * 한 벡터를 자신의 성분벡터의 합으로 나타내는 것을 벡터의 분해라고 한다.
* 단위 벡터
    * 크기가 1이고 방향만 가지는 벡터이다.
    * 벡터의 방향만을 나타낸다.
    * XYZ 좌표계에서 단위 벡터는 i,j,k에 햇을 붙여 표시한다.
    * 다른 말로 기저 벡터(basis)라고 한다.
<br><br>

### [벡터의 연산]
* 공간 상의 위치는 벡터량이다.
* 위치의 변화인 변위(displacement)도 벡터량이다.
* 벡터의 덧셈
    * r = a + b
    * 교환 법칙이 성립한다. a + b = b + a
    * 결합 법칙이 성립한다. (a + b) + c = a + (b + c)
    * 삼각형법, 평행사변형법으로 표현 가능하다.
    * 성분으로 해도 연산은 같게 나온다.
    * r = r_x + r_y = (a_x + b_x) + (a_y + b_y)
* 벡터의 뺄셈
    * r = a - b
    * 교환 법칙이 성립한다.
    * 결합 법칙이 성립한다.
    * 음벡터를 덧셈한 것과 같다.
* 벡터의 곱셈, 내적
    * inner product, dot product, (⋅)로 표시
    * 결과가 스칼라 이다.
    * a⋅b = |a| |b| cosθ
    * 방향이 일치하는 만큼 곱한다.
    * 방향이 같으면 스칼라로 곱한 것과 일치한다.
    * 방향이 90도 이면 0이다.
    * 한 벡터를 다른 벡터로 projection 해서 곱하는 것이다.
    * 교환법칙이 성립한다. a⋅b = b⋅a
    * a⋅b = a_x b_x + a_y b_y
* 벡터의 곱셈, 외적
    * outer product, cross product, (×)로 표시
    * 결과가 벡터 이다.
    * a×b = |a| |b| sinθ, 결과의 방향은 ab 평면에 수직이다.
    * 방향이 같으면 0이 된다.
    * 방향이 90도 이면 평면에 수직인 방향이 되므로 아래와 같다.
    * (XYZ 좌표계에서 i×j = k 가 된다.)
    * 교환법칙이 성립하지 않는다. a×b = -b×a
<br><br>

### [행렬 기본]
* 행렬의 정의
    * (행, 가로, i)와 (열, 세로, j)의 순서쌍으로 이루어진다.
    * 성분
        * 성분 entry, 원소 element, 계수 coefficient
        * 행렬 A_ij의 i번째 행, j번째 열에 있는 것을 뜻한다.
    * 대각선에 있는 성분을 대각 성분 diagonal entry 라고 한다.
    * 행렬의 크기는 행과 열의 수의 순서쌍 (m,n)으로 표시한다.
    * 행과 열의 수가 같으면 정사각행렬, 정방행렬 이라고 한다.
    * 행의 수가 1이면 행벡터 라고 한다.
    * 열의 수가 1이면 열벡터 라고 한다.
* 행렬의 덧셈
    * 행렬의 크기가 같다면 쉽게 가능하다.
    * 위치가 같은 원소들끼리 더해준다.
    * 교환법칙이 성립한다.
* 행렬의 상수배
    * 모든 원소에 상수를 곱해준다.
* 행렬의 곱
    * 앞 행렬(m,n)의 n과 뒷 행렬(m,n)의 m의 크기가 같아야 가능하다.
    * 앞 행렬의 m행과 뒷 행렬의 n열을 내적하여 (m,n) 요소를 만든다.
    * 교환법칙이 성립하지 않는다.
* 전치행렬
    * A^(T)
    * 행렬을 주대각선을 기준으로 뒤집어 놓은 형태이다.
    * 정사각행렬이 아니더라도 전치할 수 있다.
    * (A^(T))^(T) = A
* 역행렬
    * A^(-1)
    * 공식을 따라서 구할 수 있다.
<br><br>

### [기타 특수 행렬]
* 
<br><br>


### [선형 방정식]
* 정의
    * linear equation
    * a_1 x_1 + a_2 x_2 + ... + a_n x_n = b
    * x에 대한 차수가 1차로 이루어진 방정식.
    * x에 대한 차수가 2차이거나 음수면 비선형 방정식이다.
* 선형 방정식 계
    * a system of linear equation, linear system
    * 2개 이상의 선형 방정식이 있을 때 집합으로 부를 수 있다.
    * 같은 변수들을 포함한 선형 방정식이 1개 또는 그 이상의 집합을 뜻한다.
    * 같은 변수가 반드시 1개 이상 있어야 한다.
* 해의 집합
    * solution set
    * 선형 시스템에서 모든 가능한 해의 집합
    * 2개의 직선은 1개 점의 해를 갖는다.
    * 2개의 면은 직선으로 된 해의 집합을 갖는다.
    * 같은 솔루션 셋을 가지면 상등 equivalent 라고 한다.
* 해 solution
    * no solution, inconsistent, 평행한 직선 방정식
    * exactly one solution, consistent, 해가 1개 이상 있는 경우
    * infinitely many solution, 직선이 겹치는 경우
    * 선형 방정식 계는 위 3가지 경우만 있다.
    * 2개의 해가 존재하는 경우는 비선형이다.
* 행렬의 표시
    * 계수행렬 coefficient matrix, b를 제외하고 x계수인 a들로만 구성
    * 첨가행렬 augmented matrix, b까지 포함한 구성
<br><br>

### [가우스 소거법]
* elimination
* 행관점과 열관점 2가지로 접근
* 변수가 2개일 때
    * 행관점
        * 우리가 평소에 하던 방법
        * 두 선의 교점 찾는 것으로 풀이
        * 행으로 나눠서 2개의 행으로 취급
        * (=2개의 방정식)
        * y나 x를 소거해서 값 찾기
    * 열관점
        * 선형대수에서 푸는 방법
        * 컬럼의 결합으로 풀이
        * x와 y로 묶어서 컬럼으로 만들기
        * x에 대한 벡터, y에 대한 벡터로 표현
        * 2x - y = 1
        * x + y = 5
        * x [2, 1] + y [-1, 1] = [1, 5]
        * 4사분면에 (2,1)벡터와 (-1,1)벡터 표시
        * 해는 (1,5) 이게 곧 도착점
        * 각 벡터에 몇 상수배를 해야하는지 계산
        * 2배 곱해서 (4,2) 와 3배 곱해서 (-3,3)이 되어야 한다.
* 가우스 소거법
    * 한 행을 상수배 하여 다른 행에 더할 수 있다. (replacement)
    * 두 행을 교환할 수 있다. (interchange)
    * 0이 아닌 상수를 행에 곱할 수 있다. (scaling)
    * 결론적으로 상하 삼각행렬을 만들어 해를 찾는다.
    * 상삼각행렬
        * 단위행렬의 요소가 모두 1 이다.
        * 오른쪽 위 요소는 값이 있다.
        * 왼쪽 아래 요소는 0 이다.
    * 하삼각행렬
        * 단위행렬의 요소가 모두 1 이다.
        * 왼쪽 아래 요소는 값이 있다.
        * 오른쪽 위 요소는 0 이다.
    * 프로세스
        * x_1, x_2, x_3의 변수가 있는 예시
        * 선형 방정식 계를 `첨가행렬`로 표현한다.
        * 첫번째 행 외에 모든 행의 x_1을 0으로 만든다.
        * 첫번째 두번째 행 외에 모든 행의 x_2를 0으로 만든다.
        * 행렬에서 좌측하단이 0으로 가득찬 삼각행렬이 된다.
        * 마지막 행은 x_3의 계수만 있고, 계수를 1로 만든다.
        * 두번째 행을 x_2의 계수만 남기고 모두 없애주고, 계수를 1로 만든다.
        * 첫번째 행을 x_1의 계수만 남기고 모두 없애주고, 계루를 1로 만든다.
        * 각 변수의 값이 가우스 소거법에 의해 계산 완료 되었다.
<br><br>

### [선형 방정식 예외]
* 두개의 평면이 평행한 경우 (no solution)
    * 두개가 평행하면 만나지 않으므로 해가 없다.
* 세개의 평면이 평행한 경우
* 세개의 평면이 평행하지 않는 경우 (no intersection)
    * 삼각형 모양으로 되서 3개 변수를 모두 만족하는 해는 없어진다.
* 세개의 평면이 한 선에서 만나는 경우 (infinity of solution)
    * 선에서 만나므로 해가 무수히 많다.
* 세개의 컬럼이 동일한 평면에 놓이고 b는 다른 평면에 위치하는 경우 (no solution)
* 세개의 컬럼이 동일한 평면에 놓이고 b가 동일한 평면에 위치하는 경우 (infinity of solution)
<br><br>

### [역행렬]
* 역행렬이 존재하는 행렬 invertible matrix
    * row 개수와 col 개수가 같아야 한다.
    * AC = I 인 행렬 C가 있어야 하며 C는 유일해야 한다.
    * 이때 C를 A^(-1)으로 표시한다.
* 2x2 행렬의 결정자 determinant, (det = ad-bc)
    * A가 2x2 행렬일 때 ad-bc != 0 이면 A는 invertible 이다.
    * 역행렬이 있는지 없는지를 결정하기 때문에 결정자라고 부른다.
* 역행렬을 양변에 곱하면 쉽게 해를 구할 수 있다.
* (AB)^(-1) = B^(-1) A^(-1), 순서가 바뀐다.
* A가 invertible 이면 A의 전치행렬도 invertible 이다.
<br><br>


### [기본행렬]
* elementary matrix, E
* 항등행렬 I에 단일 기본 행연산을 적용해서 얻을 수 있다.
* replacement, interchange, scaling을 적용한 기본행렬이 있다.
* E가 invertible 이면 E^(-1)이 있는 것인데 이것도 기본행렬 E 이다.
* 역행렬을 찾는 알고리즘
    * [A I]를 [I A^(-1)]로 바꿔준다.
    * 이 과정에서 기본행렬을 여러종류 반복해서 사용할 수 있다.
    * 다시 말해 row operation을 계속 사용해서 왼쪽을 I로 만든다.
<br><br>

### [역행렬의 특징]
* 역선형 변환
    * invertible linear transformation
    * x에 A를 곱해서 다른 차원으로 multiplication 할 수 있다.
    * 다시 A^(-1)를 곱해서 원래 차원으로 multiplication 할 수 있다.
    * linear transformation은 항상 standard matrix가 있다.
<br><br>

### [LU 분해]
* 분해
    * factorization, decomposition
    * 하나의 행렬을 2개 이상의 행렬 곱으로 표현한 식
    * A = BC
* LU decomposition
    * 방정식을 푸는 방법 중 하나
    * 행 줄임 (row reduction)으로 A를 LU 분해하여 방정식을 푼다.
    * L: a unit lower triangular matrix, 하삼각행렬
    * U: echelon form, 사다리꼴행렬
    * LU 분해 방법은 역행렬 방법보다 3배 빠르다.
* LU 디컴포지션으로 해 찾기
    * Ax=b
    * A=LU 이므로, LUx=b
    * Ux=y 로 치환하면, Ly=b
    * LUx=Ly=b 이다.
    * Ux에서 값을 구하면 y의 해가 나온다.
    * Ly에서 값을 구하면 x의 해 b를 찾을 수 있다.
    * L과 U는 변수를 0으로 만드는 쉬운 형태이므로, 빠르게 문제를 푸는 원리.
    * 차원 개념
        * x에 U를 곱해서 y로 옮기고 L을 곱해서 b로 옮긴다.
    * 요약
        * Ax=b
        * LUx=b, Ux로 y 구하기
        * L(y)=b, Ly로 b 구하기
* LU 구하는 방법
    * A가 row replacement만 이용해서 U가 될 수 있다고 가정하자.
    * U가 되기 위해서 많은 row operation을 하는데 이것들은 기본행렬의 집합 E들 이다.
    * 이 기본행렬 E들의 역행렬이 L이다.
    * 노가다 혹은 공식을 사용한다.
* LU의 형태
    * A = LU 인데, A의 형태가 (m x n)이면,
    * L의 형태는 (m x m)으로 정방이며 하삼각행렬 이다.
    * U의 형태는 (m x n)으로 사다리꼴행렬 이다.
* LU 분해 구하기 노가다
    * L은 하삼각행렬이 되어야 한다.
    * L의 단위행렬 요소에 1을 넣고, 오른쪽 위는 0을 채운다.
    * L의 나머지 부분은 상수 l_ab를 넣는다.
    * U는 사다리꼴 행렬이 되어야 한다.
    * U의 단위행렬 요소와 오른쪽 위에 상수 u_ab를 넣는다.
    * U의 나머지 부분을 0으로 채운다.
    * A = LU 로 두고 LU의 행렬곱을 연산한다.
    * 나온 방정식들을 연립방정식으로 풀어 모든 상수를 구한다.
* LU 분해 구하기 공식
    * 형태: A = (4 x 5)이면, L = (4 x 4), U = (4 x 5) 이다.
    * U 구하기
    * A에서 출발해서 사다리꼴행렬으로 만드는 과정
    * 1번째 컬럼 x_1에 대하여 2~4번째 행의 계수를 0으로 만든다.
    * 2번째 컬럼 x_2에 대하여 3~4번째 행의 계수를 0으로 만든다.
    * 4번째 컬럼 x_4에 대하여 4번째 행의 계수를 0으로 만든다.
    * 결과가 사다리꼴행렬으로 U를 구했다.
    * L 구하기
    * A의 요소를 가져와서 하삼각행렬으로 만드는 과정
    * A의 1번째 컬럼 요소만 가져온다.
    * 4개 요소를 가져왔으며, 1번째 행의 계수가 1이 되게 나눈다.
    * L의 1번째 컬럼으로 작성한다.
    * U를 만드는 과정에 2~4번째 행의 x_1 계수가 0이된 중간과정을 사용한다.
    * x_1의 계수가 0인 3개 행의 2번째 컬럼의 요소만 가져온다.
    * 3개 요소를 가져왔으며, 2번째 행의 계수가 1이 되게 나눈다.
    * L의 2번째 컬럼으로 작성한다.
    * U를 만드는 과정에 3~4번째 행의 x_2 계수가 0이된 중간과정을 사용한다.
    * x_2의 계수가 0인 2개 행의 3번째 컬럼의 요소만 가져온다.
    * 2개 요소를 가져왔으며, 3번째 행의 계수가 1이 되게 나눈다.
    * L의 3번째 컬럼으로 작성한다.
    * U를 만드는 과정에 4번째 행의 x_4 계수가 0이된 중간과정을 사용한다.
    * x_4의 계수가 0인 1개 행의 5번째 컬럼의 요소만 가져온다.
    * 1개 요소를 가져왔으며, 4번째 행의 계수가 1이 되게 나눈다.
    * L의 4번째 컬럼으로 작성한다.
    * 결과가 하삼각행렬으로 L을 구했다.
<br><br>

### [행렬식]
* determinant, 역행렬이 있는지 결정
* det != 0 일때 역행렬이 존재 한다.
* 역행렬이 존재하는 것은 곧 해가 존재한다는 말이다.
* 추가 개념
    * rank: 행렬 A의 피벗 컬럼 개수 (=차원 수, dim 수)
    * pivot col: 피벗 컬럼, row reduction 후 x 계수가 살아있는 컬럼
    * null space: 피벗 컬럼이 아닌 컬럼
    * 전체 dim 수 = pivot col 수 + null space 수
    * rank 수 = pivot col 수
* 3x3 에서 det
    * 전자기학
    * det A = a_11 det A_11 - a_12 det A_12 + a_13 det A_13
* 여인수
    * cofactor, C_ij
    * 코팩터를 이용하면 det을 여러가지 형태로 표현할 수 있다.
    * 이것을 여인수 전개(cofactor expansion)이라고 한다.
    * C_ij = (-1)^(i+j) det A_ij 이다.
    * cofactor의 부호는 (-1)^(i+j)로 나타낸다.
    * (플러스와 마이너스가 격자형태로 진행되는 부호에 대한 행렬)
    * 따라서 det A = a_11 C_11 + ... + a_1n C_1n 이다.
    * 코팩터를 이용하면 임의의 row와 col으로 det을 표현할 수 있다.
    * 따라서 0이 많은 row나 col을 선택해서 det을 계산하면 된다.
* det과 곱셈
    * det AB = (det A)(det B)
    * 곱셈을 풀어서 det을 구한것과 값이 같다.
    * 덧셈은 보통 안된다.
    * det EA = (det E)(det A)
    * 기본행렬은 분해해서 빼낼 수 있다.
* 삼각행렬의 det
    * det A = a_11 a_22 a_33
    * 삼각행렬에서는 det A를 구할 때 A의 대각 텀을 곱하면 끝난다.
* 전치행렬의 det
    * A^(T) 전치행렬의 det은 det A와 동일하다.
<br><br>

### [고유벡터와 고유값]
* Eigenvector, Eigenvalue
* 행렬과 어떤 벡터의 곱셈 결과 벡터가 동일한 선상에 존재하는 경우가 있더라.
* Ax = λx 를 만족하는 0이 아닌 벡터를 고유벡터 Eigenvector 라고 한다.
* x가 nontrivial solution을 가지고 있으면 (det != 0 이면) λ를 고유값 Eigenvalue라고 한다.
* 반대로 계산하면 (A - λI) = 0 이다.
* 아이겐벡터들은 모두 직교한다.
* 고유공간 Eigenspace
    * λ가 아이겐벨류 이면, (A-λI)=0은 solution을 가진다.
    * 고유공간 Eigenspace는 (A-λI)의 null space를 의미한다.
* 삼각행렬의 아이겐벨류
    * 삼각행렬의 아이겐벨류는 대각 텀의 값이다.
* 전치행렬의 아이겐벨류
    * A^(T) 전치행렬의 아이겐벨류는 A와 동일한 값이다.
<br><br>

### [특성 방정식]
* characteristic equation
* det(A-λI)=0 을 특성방정식이라고 한다.
* λ가 특성방정식을 만족하면 λ는 행렬 A의 아이겐벨류 이다.
* 유사도 similarity
    * n차 방정식에서 아이겐벨류를 찾을때 사용한다.
    * A = PBP^(-1) 일때, A는 B에 similar 하다.
    * similarity transformation, A = P^(-1)BP로 변환하는 작업.
    * A와 B가 similar 이고, 동일한 특성을 가지면 같은 아이겐벨류를 가진다.
    * similar 한 경우에 아이겐벨류는 같지만 아이겐벡터 스페이스가 다르다.
    * det(A-λI) = det(B-λI)
<br><br>

### [대각화]
* diagonalization
* 정사각행렬 A가 대각행렬 D와 similar 하면, A를 대각화 가능하다.
* A = P^(-1)DP 일 때, A를 diagonalizable 이라고 한다.
* D는 대각 텀만 가지고 있는 정사각형이다.
* A를 D로 만드는 과정을 대각화 diagonalization 이라고 한다.
* P는 아이겐벡터로 구할 수 있는 아이겐 매트릭스 이다.
* A는 n개의 아이겐벡터를 가지고 있고 이 컬럼들을 이어 붙인게 P 이다.
* D는 주대각선에 A의 아이겐벨류들을 하나씩 적은 것이다.
* A = PDP^(-1) 이므로 AP=PD 로 나타낼 수 있다.
* 이 형태는 Ax=λx 와 관련이 있다.
<br><br>

### [대칭 행렬의 대각화]
* 대칭 행렬
    * symmetric matrix
    * A^(T) = A
    * 정사각행렬이고 전치 행렬이 자기 자신과 같은 행렬이다.
    * 주대각선을 기준으로 요소가 거울상으로 같다.
* 대칭 행렬 대각화
    * 대칭행렬에서 아이겐벡터들은 모두 직교한다.
    * 대칭행렬에서 아이겐벡터들은 선형 독립 집합이다.
    * 과정
        * 아이겐벡터를 정규화하고 직교 벡터로 표현한다. (그람-슈미트)
        * 아이겐벡터를 이어 붙여서 P를 만든다.
        * D는 주대각선에 A의 아이겐벨류들을 하나씩 적은 것이다.
        * 이때 P는 모든 컬럼이 직교하므로 P^(T) = P^(-1) 이다.
        * 따라서 A를 대각화 할 때 A=PDP^(T) 로 나타내도 된다.
* 스펙트럼 정리
    * A의 아이겐벨류 집합 D를 A의 스펙트럼이라고 한다.
    * A가 대칭행렬일 경우에 다음 4개 정리를 따른다.
    * A가 n개의 아이겐벨류를 가지고 있으면 multiplicity를 계산할 수 있다.
    * 아이겐 스페이스의 차원은 아이겐벨류의 multiplicity와 동일하다.
    * 아이겐 스페이스는 서로 직교하고, 아이겐벡터도 직교한다.
    * A는 orthogonally 대각화 가능 하다.
* 스펙트럼 분해
    * spectral decomposition
    * 스펙트럼은 곧 D이고 이건 아이겐벨류 이다.
    * A를 아이겐벨류로 표현되는 조각들로 분해하는 것이다.
    * 과정
        * A = P^(-1)DP 이므로, A=PDP^(T)로 나타낼 수 있다.
        * A를 PD와 P^(T) 의 곱으로 표현한 것을 스펙트럼 분해라고 한다.
<br><br>

### [특이값 분해]
* SVD, singular value decomposition
* 대칭 행렬의 대각화는 대칭에서만 가능하고 정사각행렬만 가능하다.
* SVD는 행렬의 크기와 상관없이 가능하다.
* (m,n) 크기의 행렬 A의 특이값 singular values 구하는 방법
    * A^(T)A은 (n,n) 크기의 대칭행렬이 된다.
    * 대칭행렬은 전치를 해도 원래 행렬이 되는 특징이 있다.
    * A^(T)A 행렬을 대각화 -> 아이겐벨류 λ 구하기 -> 루트 씌우기
    * 이 결과가 A행렬의 특이값 이다.
* A = U Σ V^(T) 로 표시한다. (PDP^(T)와 같은 형태)
* Σ
    * 시그마 행렬
    * (m,n) 크기
    * (r,r) 크기의 대각 요소가 곧 특이값(루트 λ)
    * 각 특이값을 σ_1, ..., σ_n 로 나타낸다.
* U
    * left singular 벡터
    * Av_1, ..., Av_r 을 정규화한 벡터들로 이루어진 행렬
    * 구성은 u_1, ..., u_m 이다.
* V
    * right singular 벡터
    * A^(T)A의 정규 직교 아이겐벡터로 이루어진 행렬
    * 구성은 v_1, ..., v_n 이다.
* 예시
    * A = (2, 3) 크기
    * A^(T)A 계산하면 (3,3) 크기
    * 이걸 대각화하면 아이겐벨류와 아이겐벡터를 구할 수 있다.
    * 아이겐벨류에 루트를 씌우고 A행렬 크기에 맞추면 Σ 이다.
    * 아이겐벡터는 그대로 V 이고 전치행렬 V^(T)를 구한다.
    * Av_1에 특이값 σ_1을 나눠 정규화 하면 그게 u_1이 된다.
    * m번 반복해서 U를 완성한다.
    * A = U Σ V^(T) 이다.
<br><br>



## `[정성적 의미]`
* 고유값 분해
    * eigenvalue decomposition
    * 행렬을 아이겐벨류와 아이겐벡터로 분해한다.
    * 변환에서 주 축을 찾는다.
    * PCA에서 차원 축소에 사용한다.
    * 데이터에서 중요한 정보만 남기고 압축한다.
* LU 분해
    * LU decomposition
    * 행렬을 두개의 구조(L, U)로 분해한다.
    * 대규모 데이터를 효율적으로 계산한다.
    * 선형 회귀에서 계산을 최적화한다.
* SVD
    * singular value decomposition
    * 모든 행렬에 대하여 가능하며 3개의 행렬(U, Σ, V)로 분해한다.
    * 데이터의 차원을 축소할 수 있다.
    * 데이터에 노이즈를 제거하고 중요한 패턴을 찾을 수 있다.
    * 추천 시스템에서 숨겨진 특징을 찾아낼 수 있다.
    * 고차원 이미지를 품질을 유지한 채로 낮은 차원으로 축소할 수 있다.
<br><br>





